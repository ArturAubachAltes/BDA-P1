{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation Zone - Visualització\n",
    "\n",
    "- exploitation zone de la visualització\n",
    "- preparation pipeline per taula d'entrenament del model --> cada zipcode és un indiv\n",
    "    - Shops: latitu, longitud\n",
    "    - Income: mitjana income per zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n",
    "#!pip install delta-spark\n",
    "\n",
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "#!wget -O \"HR_comma_sep.csv\" \"https://mydisk.cs.upc.edu/s/3o33yciBHADiFCD/download/HR_comma_sep.csv\"\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"Shops_Deltalake\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arxiu Parquet (de moment suposem aixo despres arreglem amb duckdb)\n",
    "shops = spark.read.parquet(\"./datalake/shops_data/2024-04-24_shops_data.parquet\")\n",
    "income = spark.read.parquet(\"./datalake/income_data/2024-04-24_IRSIncomeByZipCode_NoStateTotalsNoSmallZips.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## INCOME ##\n",
    "############\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Lista de todos los caracteres inválidos que quieres reemplazar o eliminar\n",
    "invalid_chars = [' ', ';', '{', '}', '(', ')', '\\n', '\\t', '=']\n",
    "\n",
    "# Función para limpiar los nombres de las columnas reemplazando los caracteres no válidos\n",
    "def clean_column_name(column_name):\n",
    "    for invalid_char in invalid_chars:\n",
    "        column_name = column_name.replace(invalid_char, \"_\")  # Reemplaza por subrayado o cualquier otro caracter válido que prefieras\n",
    "    return column_name\n",
    "\n",
    "# Aplicar la función de limpieza a cada columna\n",
    "cleaned_income = income.select([col(c).alias(clean_column_name(c)) for c in income.columns])\n",
    "\n",
    "# seleccionem files que ens interessen per MODEL PREDICTIU\n",
    "income_selected = cleaned_income.select(\"ZIPCODE\", \"Total_income_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "## SHOPS ##\n",
    "###########\n",
    "# canviem nom columnes perque no ens deixa accedir-hi si tenen caracters especials\n",
    "# geometry.x\n",
    "new_column_name = \"geometry_x\"\n",
    "old_column_name = \"geometry.x\"\n",
    "shops = shops.withColumnRenamed(old_column_name, new_column_name)\n",
    "\n",
    "# geometry.y\n",
    "new_column_name = \"geometry_y\"\n",
    "old_column_name = \"geometry.y\"\n",
    "shops = shops.withColumnRenamed(old_column_name, new_column_name)\n",
    "\n",
    "# attributes.shop\n",
    "new_column_name = \"shop\"\n",
    "old_column_name = \"attributes.shop\"\n",
    "shops = shops.withColumnRenamed(old_column_name, new_column_name)\n",
    "\n",
    "# attributes.name\n",
    "new_column_name = \"name\"\n",
    "old_column_name = \"attributes.name\"\n",
    "shops = shops.withColumnRenamed(old_column_name, new_column_name)\n",
    "\n",
    "# attributes.osm_id2\n",
    "new_column_name = \"index\"\n",
    "old_column_name = \"attributes.osm_id2\"\n",
    "shops = shops.withColumnRenamed(old_column_name, new_column_name)\n",
    "\n",
    "# attributes.addr_postcode\n",
    "new_column_name = \"postcode\"\n",
    "old_column_name = \"attributes.addr_postcode\"\n",
    "shops = shops.withColumnRenamed(old_column_name, new_column_name)\n",
    "\n",
    "# ens quedem només amb columnes seleccionades\n",
    "selected_columns = ['geometry_x', 'geometry_y', \"shop\", \"name\", \"index\", \"postcode\"]\n",
    "shops_selected = shops.select(selected_columns)\n",
    "\n",
    "# eliminar files que tinguin missings --> excepte les que tenen missings a postcode!!\n",
    "shops_selected = shops_selected.filter(~(col(\"geometry_x\").isNull() |\n",
    "                                col(\"geometry_y\").isNull() |\n",
    "                                col(\"shop\").isNull() |\n",
    "                                col(\"name\").isNull() |\n",
    "                                col(\"index\").isNull()))\n",
    "\n",
    "# seleccionem files que ens interessen per MODEL PREDICTIU\n",
    "shops_selected = shops.select(\"postcode\", \"geometry_x\", \"geometry_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'income_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# taula a partir de income\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_model \u001b[38;5;241m=\u001b[39m \u001b[43mincome_selected\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# renombrem columnes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_model \u001b[38;5;241m=\u001b[39m df_model\u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZIPCODE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzipcode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'income_selected' is not defined"
     ]
    }
   ],
   "source": [
    "# taula a partir de income\n",
    "df_model = income_selected\n",
    "\n",
    "# renombrem columnes\n",
    "df_model = df_model.withColumnRenamed(\"ZIPCODE\", \"zipcode\")\n",
    "df_model = df_model.withColumnRenamed(\"Total_income_amount\", \"avg_income_per_zipcode\")\n",
    "\n",
    "# renombrem columnes de zipcode a sales i shops per poder fer join\n",
    "shops_selected = shops_selected.withColumnRenamed(\"postcode\", \"zipcode\")\n",
    "\n",
    "df_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = df_model.join(shops_selected, (df_model[\"zipcode\"] == shops_selected[\"zipcode\"]), \"inner\")\n",
    "selected_columns = [df_model[col] for col in df_model.columns] + [shops_selected[col] for col in shops_selected.columns if col not in [\"zipcode\"]]\n",
    "joined_data = joined_data.select(selected_columns)\n",
    "joined_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduim valors de zipcode\n",
    "df_visualitzaciogkmgu = df_visualitzacio.withColumn(\"zipcode\", income_selected[\"ZIPCODE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalitzar sessió de Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
