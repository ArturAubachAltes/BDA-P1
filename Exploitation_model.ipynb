{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation Zone - Model Predictiu\n",
    "\n",
    "- exploitation zone del model predictiu\n",
    "- preparation pipeline per taula d'entrenament del model --> cada zipcode és un indiv\n",
    "    - Sales: 5 categories més comunes per zipcode, count vendes per zipcode, profit mitja per zipcode, mitjana num unitat per comanda per zipcode\n",
    "    - Shops: 5shops més comunes per zipcode\n",
    "    - Income: mitjana income per zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, mean, row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, when, first\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/04/25 03:49:30 WARN Utils: Your hostname, TABLET-F60ERQ04 resolves to a loopback address: 127.0.1.1; using 172.23.160.255 instead (on interface eth0)\n",
      "24/04/25 03:49:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/04/25 03:49:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/25 03:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/04/25 03:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/04/25 03:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/04/25 03:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/04/25 03:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.jars\", \"./duckdb.jar\") \\\n",
    "        .appName(\"ExploitationZone\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|ZIPCODE|Average_Income|\n",
      "+-------+--------------+\n",
      "|  35079|   168362.0000|\n",
      "|  35442|    69990.0000|\n",
      "|  36269|    17803.0000|\n",
      "|  99503|   493725.0000|\n",
      "|  72044|    16750.0000|\n",
      "|  72348|    32734.0000|\n",
      "|  72533|     4427.0000|\n",
      "|  90250|  1744745.0000|\n",
      "|  90640|  1185590.0000|\n",
      "|  91745|  1513989.0000|\n",
      "|  91766|  1049937.0000|\n",
      "|  92377|   478508.0000|\n",
      "|  92591|  1081072.0000|\n",
      "|  95005|   231483.0000|\n",
      "|  81521|   390900.0000|\n",
      "|   6811|  1123048.0000|\n",
      "|  19803|  1192053.0000|\n",
      "|  32096|    43647.0000|\n",
      "|  32277|   586959.0000|\n",
      "|  32542|    44570.0000|\n",
      "+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## INCOME ##\n",
    "############\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "average_income = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:duckdb:trusted_zone.duckdb\") \\\n",
    "    .option(\"dbtable\", \"cleaned_income\") \\\n",
    "    .option(\"driver\", \"org.duckdb.DuckDBDriver\") \\\n",
    "    .load() \\\n",
    "    .groupBy(\"ZIPCODE\") \\\n",
    "    .agg(avg(\"Total_income_amount\").alias(\"Average_Income\"))\n",
    "\n",
    "# Mostrar el resultado\n",
    "average_income.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+-------------+----------------------+\n",
      "|Postal_Code|Category_mas_comun_1|Category_mas_comun_2|Category_mas_comun_3|Average_Sales|Average_Order_Quantity|\n",
      "+-----------+--------------------+--------------------+--------------------+-------------+----------------------+\n",
      "|     1001.0|Storage & Organiz...|                NULL|                NULL|        79.05|                5.0000|\n",
      "|     1007.0|Computer Peripherals|                NULL|                NULL|         39.6|                2.0000|\n",
      "|     1013.0|          Appliances|                NULL|                NULL|        717.6|               13.0000|\n",
      "|     1027.0| Pens & Art Supplies|                NULL|                NULL|        35.28|               12.0000|\n",
      "|     1028.0|Binders and Binde...|                NULL|                NULL|        57.96|                3.0000|\n",
      "|     1040.0|Storage & Organiz...|                NULL|                NULL|       566.28|                4.0000|\n",
      "|     1056.0|              Labels|                NULL|                NULL|         99.0|               25.0000|\n",
      "|     1060.0|  Chairs & Chairmats|                NULL|                NULL|       223.44|                2.0000|\n",
      "|     1069.0|              Tables|                NULL|                NULL|          4.4|                2.0000|\n",
      "|     1075.0|              Tables|  Office Furnishings|                NULL|      348.175|               13.0000|\n",
      "|     1089.0|     Copiers and Fax|                NULL|                NULL|        445.5|                1.0000|\n",
      "|     1095.0| Pens & Art Supplies|                NULL|                NULL|        69.84|               18.0000|\n",
      "|     1106.0|Storage & Organiz...|                NULL|                NULL|        173.7|                1.0000|\n",
      "|     1108.0|Computer Peripherals|                NULL|                NULL|         16.0|                8.0000|\n",
      "|     1301.0|     Office Machines|                NULL|                NULL|        163.8|               20.0000|\n",
      "|     1420.0|     Office Machines|                NULL|                NULL|        92.16|                6.0000|\n",
      "|     1440.0|Computer Peripherals|                NULL|                NULL|       423.15|               13.0000|\n",
      "|     1450.0|Telephones and Co...|                NULL|                NULL|      3796.58|               19.0000|\n",
      "|     1453.0|Telephones and Co...|                NULL|                NULL|       372.24|                6.0000|\n",
      "|     1462.0|Telephones and Co...|                NULL|                NULL|       1077.3|                9.0000|\n",
      "+-----------+--------------------+--------------------+--------------------+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## SALES ##\n",
    "###########\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "sales_usa = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:duckdb:trusted_zone.duckdb\") \\\n",
    "    .option(\"dbtable\", \"cleaned_sales\") \\\n",
    "    .option(\"driver\", \"org.duckdb.DuckDBDriver\") \\\n",
    "    .load() \\\n",
    "    .filter(col(\"Country_/_Region\") == \"United States of America\") \\\n",
    "    .drop(\"Customer_Name\") \\\n",
    "    .select(\"ZIPCODE\", \"Category\", \"Sales\", \"Order_Quantity\")\n",
    "\n",
    "# Ventana para contar las categorías más frecuentes por código postal\n",
    "category_window = Window.partitionBy(\"ZIPCODE\").orderBy(col(\"count\").desc())\n",
    "df_category = sales_usa.groupBy(\"ZIPCODE\", \"Category\").count()\n",
    "df_category = df_category.withColumn(\"rn\", row_number().over(category_window))\n",
    "\n",
    "# Filtrar solo las top 5 categorías y pivotear\n",
    "df_category = df_category.filter(col(\"rn\") <= 5)\n",
    "pivot_category = df_category.groupBy(\"ZIPCODE\").pivot(\"rn\", [1, 2, 3]).agg(first(\"Category\"))\n",
    "\n",
    "# Renombrar las columnas para que sean más descriptivas\n",
    "b = pivot_category.select(\n",
    "    col(\"ZIPCODE\"),\n",
    "    col(\"1\").alias(\"Category_mas_comun_1\"),\n",
    "    col(\"2\").alias(\"Category_mas_comun_2\"),\n",
    "    col(\"3\").alias(\"Category_mas_comun_3\")\n",
    ")\n",
    "\n",
    "df_averages = sales_usa.groupBy(\"ZIPCODE\").agg(\n",
    "    mean(\"Sales\").alias(\"Average_Sales\"),\n",
    "    mean(\"Order_Quantity\").alias(\"Average_Order_Quantity\")\n",
    ")\n",
    "\n",
    "\n",
    "result_df = b.join(df_averages, \"ZIPCODE\", \"outer\")\n",
    "\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+-----------------+----------------+----------------+\n",
      "|postcode|shop_mas_comun_1|shop_mas_comun_2| shop_mas_comun_3|shop_mas_comun_4|shop_mas_comun_5|\n",
      "+--------+----------------+----------------+-----------------+----------------+----------------+\n",
      "|   28000|         florist|        copyshop|      supermarket|        boutique|    dry_cleaning|\n",
      "|   28017|           paint|     hairdresser|           beauty|     convenience|         clothes|\n",
      "|   28020|      car_repair|            NULL|             NULL|            NULL|            NULL|\n",
      "|   28035|           shoes|      stationery|          laundry|           paint|     convenience|\n",
      "|   28040|department_store|            NULL|             NULL|            NULL|            NULL|\n",
      "|   28450|          coffee|            NULL|             NULL|            NULL|            NULL|\n",
      "|   28459|           shoes|         butcher|      hairdresser|             yes|     convenience|\n",
      "|   28460|          bakery|         butcher|             NULL|            NULL|            NULL|\n",
      "|   28860|     supermarket|            NULL|             NULL|            NULL|            NULL|\n",
      "|   28867|     supermarket|            NULL|             NULL|            NULL|            NULL|\n",
      "|   28970|     video_games|         butcher|      electronics|     convenience|      car_repair|\n",
      "|   28974|     video_games|     convenience|             NULL|            NULL|            NULL|\n",
      "|   28975|     supermarket|             yes|             NULL|            NULL|            NULL|\n",
      "|   28978|          pastry|        hardware|      hairdresser|        flooring|          beauty|\n",
      "|   28979|         seafood|         butcher|      convenience|     hairdresser|          beauty|\n",
      "|   28987|          spices|   variety_store|cleaning_products|      pawnbroker|         clothes|\n",
      "|   28988|       cosmetics|     supermarket|            tyres|    mobile_phone|       furniture|\n",
      "|   48300|   travel_agency|            NULL|             NULL|            NULL|            NULL|\n",
      "|   48350|        computer|            NULL|             NULL|            NULL|            NULL|\n",
      "|   48570|     supermarket|            NULL|             NULL|            NULL|            NULL|\n",
      "+--------+----------------+----------------+-----------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## SHOP ##\n",
    "###########\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, row_number, first\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Asumir que SparkSession ya está inicializado como 'spark'\n",
    "\n",
    "# Cargar los datos y seleccionar columnas requeridas en un paso\n",
    "shops = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:duckdb:trusted_zone.duckdb\") \\\n",
    "    .option(\"dbtable\", \"cleaned_shops\") \\\n",
    "    .option(\"driver\", \"org.duckdb.DuckDBDriver\") \\\n",
    "    .load() \\\n",
    "    .select(\"ZIPCODE\", \"shop\")\n",
    "\n",
    "# Calcular la cantidad de cada tipo de tienda por código postal y seleccionar las 5 principales\n",
    "window_count = Window.partitionBy(\"ZIPCODE\").orderBy(col(\"count\").desc())\n",
    "top_shops = shops.groupBy(\"ZIPCODE\", \"shop\").count() \\\n",
    "    .withColumn(\"row_num\", row_number().over(window_count)) \\\n",
    "    .filter(col(\"row_num\") <= 5) \\\n",
    "    .drop(\"row_num\") \\\n",
    "    .orderBy(\"ZIPCODE\")\n",
    "\n",
    "# Pivoteamos el DataFrame para tener cada tienda en una columna separada\n",
    "window_pivot = Window.partitionBy(\"ZIPCODE\").orderBy(\"count\")\n",
    "pivot_df = top_shops.withColumn(\"rn\", row_number().over(window_pivot)) \\\n",
    "    .groupBy(\"ZIPCODE\").pivot(\"rn\", [1, 2, 3, 4, 5]).agg(first(\"shop\"))\n",
    "\n",
    "# Renombrar las columnas para hacerlas más descriptivas\n",
    "pivot_df = pivot_df.select(\n",
    "    col(\"ZIPCODE\").alias(\"ZIPCODE\"),\n",
    "    col(\"1\").alias(\"shop_mas_comun_1\"),\n",
    "    col(\"2\").alias(\"shop_mas_comun_2\"),\n",
    "    col(\"3\").alias(\"shop_mas_comun_3\"),\n",
    "    col(\"4\").alias(\"shop_mas_comun_4\"),\n",
    "    col(\"5\").alias(\"shop_mas_comun_5\")\n",
    ")\n",
    "\n",
    "# Mostrar el resultado final\n",
    "pivot_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
