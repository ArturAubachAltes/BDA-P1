{"cells":[{"cell_type":"markdown","metadata":{},"source":["Per entrar a una sessió de Spark i iniciar un builder en DeltaLake"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2Ff5OllvaQ-i"},"outputs":[{"name":"stdout","output_type":"stream","text":[":: loading settings :: url = jar:file:/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"]},{"name":"stderr","output_type":"stream","text":["Ivy Default Cache set to: /Users/aina/.ivy2/cache\n","The jars for the packages stored in: /Users/aina/.ivy2/jars\n","io.delta#delta-spark_2.12 added as a dependency\n",":: resolving dependencies :: org.apache.spark#spark-submit-parent-0da620d0-2cbc-4586-8b2f-11c3b8be6bf8;1.0\n","\tconfs: [default]\n","\tfound io.delta#delta-spark_2.12;3.1.0 in central\n","\tfound io.delta#delta-storage;3.1.0 in central\n","\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",":: resolution report :: resolve 140ms :: artifacts dl 6ms\n","\t:: modules in use:\n","\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n","\tio.delta#delta-storage;3.1.0 from central in [default]\n","\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n","\t---------------------------------------------------------------------\n","\t|                  |            modules            ||   artifacts   |\n","\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n","\t---------------------------------------------------------------------\n","\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n","\t---------------------------------------------------------------------\n",":: retrieving :: org.apache.spark#spark-submit-parent-0da620d0-2cbc-4586-8b2f-11c3b8be6bf8\n","\tconfs: [default]\n","\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n","24/04/19 11:30:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/04/19 11:30:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"]}],"source":["#!pip install pyspark\n","#!pip install delta-spark\n","\n","import pyspark\n","from delta import *\n","\n","#!wget -O \"HR_comma_sep.csv\" \"https://mydisk.cs.upc.edu/s/3o33yciBHADiFCD/download/HR_comma_sep.csv\"\n","\n","builder = pyspark.sql.SparkSession.builder.appName(\"Shops_Deltalake\") \\\n","    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n","    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n","\n","spark = configure_spark_with_delta_pip(builder).getOrCreate()"]},{"cell_type":"markdown","metadata":{},"source":["## Comandes com si estessis a una sessió de Spark\n","\n","Llegir els arxius i guardar-los en format DeltaLake, que ens garantitza que es compleixen les restriccions ACID, i dona avanatatges \n","\n","\n","\n","\n","Carregar i llegir els 3 arxius de tenim"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"inU0BE6yC-f-"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----+-------+-----------------+---------------------------+-----------+-----------------------------------+-------------------+----------------+-------------------------------------+---------------------+------------------+\n","|STATE|ZIPCODE|Number of returns|Adjusted gross income (AGI)|    Avg AGI|Number of returns with total income|Total income amount|Avg total income|Number of returns with taxable income|Taxable income amount|Avg taxable income|\n","+-----+-------+-----------------+---------------------------+-----------+-----------------------------------+-------------------+----------------+-------------------------------------+---------------------+------------------+\n","|   AL|  35004|             4930|                     255534|51.83245436|                               4930|             258024|     52.33752535|                                 4020|               163859|       40.76094527|\n","|   AL|  35005|             3300|                     128387|38.90515152|                               3300|             129390|     39.20909091|                                 2440|                70760|              29.0|\n","|   AL|  35006|             1230|                      58302|       47.4|                               1230|              58585|      47.6300813|                                  940|                36341|        38.6606383|\n","|   AL|  35007|            11990|                     643708|53.68707256|                              11990|             651350|     54.32443703|                                 9280|               414878|       44.70668103|\n","|   AL|  35010|             8320|                     378497|45.49242788|                               8320|             382106|     45.92620192|                                 5610|               226514|       40.37682709|\n","|   AL|  35014|             1610|                      67205|41.74223602|                               1610|              67885|     42.16459627|                                 1180|                38277|       32.43813559|\n","|   AL|  35016|             7030|                     329461|46.86500711|                               7030|             333226|     47.40056899|                                 5080|               204874|       40.32952756|\n","|   AL|  35019|              930|                      34909|37.53655914|                                930|              35392|     38.05591398|                                  650|                19152|       29.46461538|\n","|   AL|  35020|             9970|                     260241|26.10240722|                               9970|             262475|     26.32647944|                                 5520|               110968|       20.10289855|\n","|   AL|  35022|             9490|                     516329|54.40769231|                               9490|             521539|     54.95669125|                                 7400|               327603|       44.27067568|\n","|   AL|  35023|            10230|                     476432|46.57204301|                              10230|             480458|      46.9655914|                                 7960|               291768|       36.65427136|\n","|   AL|  35031|             2970|                     110967|37.36262626|                               2970|             112152|     37.76161616|                                 2000|                59275|           29.6375|\n","|   AL|  35033|             1340|                      66702|49.77761194|                               1340|              67437|      50.3261194|                                 1010|                41766|       41.35247525|\n","|   AL|  35034|             1440|                      51658|35.87361111|                               1440|              52030|     36.13194444|                                  950|                27832|       29.29684211|\n","|   AL|  35035|              550|                      30894|56.17090909|                                550|              31542|     57.34909091|                                  390|                20707|       53.09487179|\n","|   AL|  35040|             7130|                     355685|49.88569425|                               7130|             359868|     50.47237027|                                 5720|               221987|       38.80891608|\n","|   AL|  35042|             2220|                      95692| 43.1045045|                               2220|              96503|     43.46981982|                                 1590|                56177|       35.33144654|\n","|   AL|  35043|             4550|                     359323|78.97208791|                               4550|             363943|     79.98747253|                                 3790|               253356|       66.84854881|\n","|   AL|  35044|             3160|                     123233|38.99778481|                               3160|             124406|     39.36898734|                                 2160|                70753|       32.75601852|\n","|   AL|  35045|             5650|                     234349|41.47769912|                               5650|             236772|     41.90654867|                                 3870|               134635|       34.78940568|\n","+-----+-------+-----------------+---------------------------+-----------+-----------------------------------+-------------------+----------------+-------------------------------------+---------------------+------------------+\n","only showing top 20 rows\n","\n"]}],"source":["#Arxiu Parquet \n","income = spark.read.parquet(\"./datalake/income_data/2024-04-17_IRSIncomeByZipCode_NoStateTotalsNoSmallZips.parquet\")\n","income.show()\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"ename":"AnalysisException","evalue":"[DELTA_INVALID_CHARACTERS_IN_COLUMN_NAMES] Found invalid character(s) among ' ,;{}()\\n\\t=' in the column names of your schema. Please use other characters and try again.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m cleaned_sales \u001b[38;5;241m=\u001b[39m income\u001b[38;5;241m.\u001b[39mselect([col(c)\u001b[38;5;241m.\u001b[39malias(clean_column_name(c)) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m income\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Ahora guarda el DataFrame limpio en formato Delta\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mincome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deltalake/income_data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","\u001b[0;31mAnalysisException\u001b[0m: [DELTA_INVALID_CHARACTERS_IN_COLUMN_NAMES] Found invalid character(s) among ' ,;{}()\\n\\t=' in the column names of your schema. Please use other characters and try again."]}],"source":["from pyspark.sql.functions import col\n","\n","# Lista de todos los caracteres inválidos que quieres reemplazar o eliminar\n","invalid_chars = [' ', ';', '{', '}', '(', ')', '\\n', '\\t', '=']\n","\n","# Función para limpiar los nombres de las columnas reemplazando los caracteres no válidos\n","def clean_column_name(column_name):\n","    for invalid_char in invalid_chars:\n","        column_name = column_name.replace(invalid_char, \"_\")  # Reemplaza por subrayado o cualquier otro caracter válido que prefieras\n","    return column_name\n","\n","# Aplicar la función de limpieza a cada columna\n","cleaned_sales = income.select([col(c).alias(clean_column_name(c)) for c in income.columns])\n","\n","# Ahora guarda el DataFrame limpio en formato Delta\n","income.write.mode(\"overwrite\").format(\"delta\").save(\"./deltalake/income_data/\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN856KMaB+xcd49X0OG6wJE","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
